{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared library loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# import open3d as o3d\n",
    "from pointnet.model import PointNetCls\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from show3d_balls import showpoints\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from pointnet.model import PointNetDenseCls\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_off(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # if lines[0].strip() != 'OFF':\n",
    "        #     raise ValueError('Not a valid OFF header')\n",
    "\n",
    "        parts = lines[1].strip().split()\n",
    "        num_vertices = int(parts[0])\n",
    "\n",
    "        vertices = []\n",
    "        for i in range(2, 2 + num_vertices):\n",
    "            vertex = list(map(float, lines[i].strip().split()))\n",
    "            vertices.append(vertex)\n",
    "\n",
    "        return np.array(vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二. 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_off_file(filename):\n",
    "    \"\"\"读取OFF文件并提取点云数据\"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        if lines[0].strip() != 'OFF':\n",
    "            raise ValueError('Not a valid OFF file')\n",
    "\n",
    "        n_verts, n_faces, _ = map(int, lines[1].strip().split())\n",
    "        verts = [list(map(float, line.strip().split())) for line in lines[2:2 + n_verts]]\n",
    "\n",
    "        return np.array(verts, dtype=np.float32)\n",
    "\n",
    "def segment_point_cloud(points_arr, segment_model_path): \n",
    "\n",
    "    # 读取OFF文件，提取点云数据\n",
    "    point = torch.from_numpy(points_arr).float()\n",
    "\n",
    "    # 加载预训练模型\n",
    "    state_dict = torch.load(segment_model_path)\n",
    "\n",
    "    # 初始化分类器\n",
    "    classifier = PointNetDenseCls(k=state_dict['conv4.weight'].size()[0])\n",
    "\n",
    "    # 加载模型参数\n",
    "    classifier.load_state_dict(state_dict)\n",
    "\n",
    "    # 切换模型为评估模式\n",
    "    classifier.eval()\n",
    "\n",
    "    # 检查是否有可用的 GPU，如果没有则使用 CPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用设备: \", device)\n",
    "\n",
    "    # 将点云数据转换为网络输入格式\n",
    "    point = point.transpose(1, 0).contiguous()\n",
    "    point = Variable(point.view(1, point.size()[0], point.size()[1]))\n",
    "\n",
    "    # 将点云数据移动到指定设备（GPU/CPU）\n",
    "    point = point.to(device)\n",
    "    classifier = classifier.to(device)\n",
    "\n",
    "    # 执行前向传播，获取预测结果\n",
    "    pred, _, _ = classifier(point)\n",
    "\n",
    "    # 获取预测类别\n",
    "    pred_choice = pred.data.max(2)[1]\n",
    "    print(pred_choice)\n",
    "\n",
    "    # 获取颜色映射，用于显示点云的颜色\n",
    "    cmap = plt.cm.get_cmap(\"hsv\", 10)\n",
    "    cmap = np.array([cmap(i) for i in range(10)])[:, :3]\n",
    "    pred_color = cmap[pred_choice.cpu().numpy()[0], :]\n",
    "\n",
    "    # 显示点云和预测结果\n",
    "    showpoints(points_arr, pred_color, pred_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z. 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_point_cloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./seg/seg_model_Chair_0.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m ply_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_datesets.lee/chair_0011.off\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43msegment_point_cloud\u001b[49m(load_off(ply_file), model_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segment_point_cloud' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = './seg/seg_model_Chair_0.pth'\n",
    "ply_file = './test_datesets.lee/chair_0011.off'\n",
    "segment_point_cloud(load_off(ply_file), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39forPointNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
