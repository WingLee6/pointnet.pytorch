{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# import open3d as o3d\n",
    "from pointnet.model import PointNetCls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply(file_path):\n",
    "    # 使用 open3d 读取 PLY 文件\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    # 提取点云数据（x, y, z坐标）\n",
    "    points = np.asarray(pcd.points)\n",
    "    return points\n",
    "\n",
    "def load_off(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # if lines[0].strip() != 'OFF':\n",
    "        #     raise ValueError('Not a valid OFF header')\n",
    "\n",
    "        parts = lines[1].strip().split()\n",
    "        num_vertices = int(parts[0])\n",
    "\n",
    "        vertices = []\n",
    "        for i in range(2, 2 + num_vertices):\n",
    "            vertex = list(map(float, lines[i].strip().split()))\n",
    "            vertices.append(vertex)\n",
    "\n",
    "        return np.array(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {\n",
    "    0: \"airplane\",\n",
    "    1: \"bag\",\n",
    "    2: \"cap\",\n",
    "    3: \"car\",\n",
    "    4: \"chair\",\n",
    "    5: \"earphone\",\n",
    "    6: \"guitar\",\n",
    "    7: \"knife\",\n",
    "    8: \"lamp\",\n",
    "    9: \"laptop\",\n",
    "    10: \"motorbike\",\n",
    "    11: \"mug\",\n",
    "    12: \"pistol\",\n",
    "    13: \"rocket\",\n",
    "    14: \"skateboard\",\n",
    "    15: \"table\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二. 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_points(points, num_points=2500):\n",
    "    if points.shape[0] < num_points:\n",
    "        # 如果点数不足2500，进行补零\n",
    "        points = np.pad(points, ((0, num_points - points.shape[0]), (0, 0)), mode='constant')\n",
    "    elif points.shape[0] > num_points:\n",
    "        # 如果点数超过2500，进行随机下采样\n",
    "        indices = np.random.choice(points.shape[0], num_points, replace=False)\n",
    "        points = points[indices]\n",
    "    return points\n",
    "\n",
    "def classify_point_cloud(points_arr, model_path):\n",
    "    # 加载模型\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classifier = PointNetCls(k=16)  # 根据你的数据集类别数调整k的值\n",
    "    classifier = classifier.to(device)\n",
    "    classifier.load_state_dict(torch.load(model_path))\n",
    "    classifier.eval()\n",
    "\n",
    "    # 加载和预处理点云数据\n",
    "    points = preprocess_points(points_arr)\n",
    "    points = torch.tensor(points, dtype=torch.float32).unsqueeze(0)  # 添加批次维度\n",
    "\n",
    "    # 转置点云数据以符合网络输入格式\n",
    "    points = points.transpose(2, 1).to(device)\n",
    "\n",
    "    # 模型推断\n",
    "    with torch.no_grad():\n",
    "        pred, _, _ = classifier(points)\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        print(f\"Predicted class index: {pred_choice.item()}, Predicted class name: {CLASS_MAP[pred_choice.item()]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z. 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: 8, Predicted class name: lamp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/8wypyv693cq1xfjg3yz9xmm80000gn/T/ipykernel_10500/1196281279.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "model_path = './cls/cls_model_0.pth'\n",
    "ply_file = './test_datesets.lee/chair_0011.off'\n",
    "classify_point_cloud(load_off(ply_file), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39forPointNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
